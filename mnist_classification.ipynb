{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tseyi-SLB/dotfiles/blob/master/mnist_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEXLKO-LGMCH"
      },
      "source": [
        "# MNIST Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4ukwpu7GMCI"
      },
      "source": [
        "üéØ <b><u>Exercise objectives</u></b>\n",
        "- Understand the *MNIST* dataset\n",
        "- Design your first **Convolutional Neural Network** (*CNN*) and answer questions such as:\n",
        "    - what are *Convolutional Layers*?\n",
        "    - how many *parameters* are involved in such a layer?\n",
        "- Train this CNN on images"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9OvccMqGGtE_",
        "outputId": "2ac2eff7-4c9d-470c-ba16-ab2a16b6a03b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhed-KBeGMCJ"
      },
      "source": [
        "üöÄ <b><u>Let's get started!</u></b>\n",
        "\n",
        "Imagine that we are  back in time into the 90's.\n",
        "You work at a *Post Office* and you have to deal with an enormous amount of letters on a daily basis. How could you automate the process of reading the ZIP Codes, which are a combination of 5 handwritten digits?\n",
        "\n",
        "This task, called the **Handwriting Recognition**, used to be a very complex problem back in those days. It was solved by *Bell Labs* (among others) where one of the Deep Learning gurus, [*Yann Le Cun*](https://en.wikipedia.org/wiki/Yann_LeCun), used to work.\n",
        "\n",
        "From [Wikipedia](https://en.wikipedia.org/wiki/Handwriting_recognition):\n",
        "\n",
        "> Handwriting recognition (HWR), also known as Handwritten Text Recognition (HTR), is the ability of a computer to receive and interpret intelligible handwritten input from sources such as paper documents, photographs, touch-screens and other devices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OIQVG25GMCJ"
      },
      "source": [
        "![Number recognition](recognition.gif)\n",
        "\n",
        "*Note: The animation above is just here to help you visualize what happens with the different images: <br/> $\\rightarrow$ For each image, once the CNN is trained, it will predict what digit is written. The inputs are the different digits and not one animation/video!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BbadCGCdGMCJ"
      },
      "source": [
        "ü§î <b><u>How does this CNN work ?</u></b>\n",
        "\n",
        "- *Inputs*: Images (_each image shows a handwritten digit_)\n",
        "- *Target*: For each image, you want your CNN model to predict the correct digit (between 0 and 9)\n",
        "    - It is a **multi-class classification** task (more precisely a 10-class classification task since there are 10 different digits).\n",
        "\n",
        "üî¢ To improve the capacity of the Convolutional Neural Network to read these numbers, we need to feed it with many images representing handwritten digits. This is why the üìö [**MNIST dataset**](http://yann.lecun.com/exdb/mnist/) *(Mixed National Institute of Standards and Technology)* was created."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "dHADnHH_GMCJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leN3z73EGMCK"
      },
      "source": [
        "## (1) The `MNIST` Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVdjLmx7GMCK"
      },
      "source": [
        "üìö Tensorflow/Keras offers multiple [**datasets**](https://www.tensorflow.org/api_docs/python/tf/keras/datasets) to play with:\n",
        "- *Vectors*: `boston_housing` (regression)\n",
        "- *Images* : `mnist`, `fashion_mnist`, `cifar10`, `cifar100` (classification)\n",
        "- *Texts*: `imbd`, `reuters` (classification/sentiment analysis)\n",
        "\n",
        "\n",
        "üíæ You can **load the MNIST dataset** with the following commands:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44Gj8j_aGMCK",
        "outputId": "adac98dd-6613-4a89-f6a8-7681c2383699"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((60000, 28, 28), (60000,)), ((10000, 28, 28), (10000,)))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from tensorflow.keras import datasets\n",
        "\n",
        "\n",
        "# Loading the MNIST Dataset...\n",
        "(X_train, y_train), (X_test, y_test) = datasets.mnist.load_data(path=\"mnist.npz\")\n",
        "\n",
        "# The train set contains 60 000 images, each of them of size 28x28\n",
        "# The test set contains 10 000 images, each of them of size 28x28\n",
        "(X_train.shape, y_train.shape), (X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGDwZg26GMCK"
      },
      "source": [
        "### (1.1) Exploring the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOmzWLcfGMCK"
      },
      "source": [
        "‚ùì **Question: Let's have look at some handwritten digits of this MNIST dataset.** ‚ùì\n",
        "\n",
        "üñ® Print some images from the *train set*.\n",
        "\n",
        "<details>\n",
        "    <summary><i>Hints</i></summary>\n",
        "\n",
        "üí°*Hint*: use the `imshow` function from `matplotlib` with `cmap = \"gray\"`\n",
        "\n",
        "ü§® Note: if you don't specify this *cmap* argument, the weirdly displayed colors are just Matplotlib defaults...\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "bbzhnMHwGMCK",
        "outputId": "90391b9c-413f-4ab2-c570-6b11e33212f2"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Print some random images\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(X_train[0], cmap=\"gray\");\n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(X_train[1], cmap=\"gray\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJWt-HS6GMCK"
      },
      "source": [
        "### (1.2) Image Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOEQcHLtGMCL"
      },
      "source": [
        "‚ùóÔ∏è **Neural Networks converge faster when the input data is somehow normalized** ‚ùóÔ∏è\n",
        "\n",
        "üë©üèª‚Äçüè´ How do we proceed for Convolutional Neural Networks ?\n",
        "* The `RBG` intensities are coded between 0 and 255.\n",
        "* We can simply divide the input data by the maximal value 255 to have all the pixels' intensities between 0 and 1 üòâ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a18KvdCGMCL"
      },
      "source": [
        "‚ùì **Question ‚ùì As a first preprocessing step, please normalize your data.**\n",
        "\n",
        "Don't forget to do it both on your train data and your test data.\n",
        "\n",
        "(*Note: you can also center your data, by subtracting 0.5 from all the values, but it is not mandatory*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "nOmXUbW3GMCL"
      },
      "outputs": [],
      "source": [
        "# Image processing\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8J1_ryGGMCL"
      },
      "source": [
        "### (1.3) Inputs' dimensionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fv9_y9UxGMCL",
        "outputId": "9b0eca3e-f6db-44be-9830-6179d533f01b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inq8Lm1HGMCL"
      },
      "source": [
        "üëÜ Remember that you have 60,000 training images and 10,000 test images, each of size $(28, 28)$. However...\n",
        "\n",
        "> ‚ùóÔ∏è  **`Convolutional Neural Network models need to be fed with images whose last dimension is the number of channels`.**  \n",
        "\n",
        "> üßëüèª‚Äçüè´ The shape of tensors fed into ***ConvNets*** is the following: `(NUMBER_OF_IMAGES, HEIGHT, WIDTH, CHANNELS)`\n",
        "\n",
        "üïµüèªThis last dimension is clearly missing here. Can you guess the reason why?\n",
        "<br>\n",
        "<details>\n",
        "    <summary><i>Answer<i></summary>\n",
        "        \n",
        "* All these $60000$ $ (28 \\times 28) $ pictures are black-and-white $ \\implies $ Each pixel lives on a spectrum from full black (0) to full white (1).\n",
        "        \n",
        "    * Theoretically, you don't need to know the number of channels for a black-and-white picture since there is only 1 channel (the \"whiteness\" of \"blackness\" of a pixel). However, it is still mandatory for the model to have this number of channels explicitly stated.\n",
        "        \n",
        "    * In comparison, colored pictures need multiple channels:\n",
        "        - the RGB system with 3 channels (<b><span style=\"color:red\">Red</span> <span style=\"color:green\">Green</span> <span style=\"color:blue\">Blue</span></b>)\n",
        "        - the CYMK system  with 4 channels (<b><span style=\"color:cyan\">Cyan</span> <span style=\"color:magenta\">Magenta</span> <span style=\"color:yellow\">Yellow</span> <span style=\"color:black\">Black</span></b>)\n",
        "        \n",
        "        \n",
        "</details>        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss2xFdDNGMCL"
      },
      "source": [
        "‚ùì **Question: expanding dimensions** ‚ùì\n",
        "\n",
        "* Use the **`expand_dims`** to add one dimension at the end of the training data and test data.\n",
        "\n",
        "* Then, print the shapes of `X_train` and `X_test`. They should respectively be equal to $(60000, 28, 28, 1)$ and $(10000, 28, 28, 1)$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "-kEeTV-AGMCL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.backend import expand_dims\n",
        "X_train = expand_dims(X_train, axis=-1)\n",
        "X_test = expand_dims(X_test, axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2AwNbTAGMCL",
        "outputId": "4afc0620-df95-45f2-c396-b2e53f9d90fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-JpMT9FGMCL"
      },
      "source": [
        "### (1.4) Target encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP5S9nhxGMCL"
      },
      "source": [
        "One more thing to for a multiclass classification task in Deep Leaning:\n",
        "\n",
        "üëâ _\"one-hot-encode\" the categories*_\n",
        "\n",
        "‚ùì **Question: encoding the labels** ‚ùì\n",
        "\n",
        "* Use **`to_categorical`** to transform your labels.\n",
        "* Store the results into two variables that you can call **`y_train_cat`** and **`y_test_cat`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "cUOVYr8CGMCL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train)\n",
        "y_test_cat = to_categorical(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZSMLSR_jGMCL"
      },
      "outputs": [],
      "source": [
        "# Quick check that you correctly used to_categorical\n",
        "assert(y_train_cat.shape == (60000,10))\n",
        "assert(y_test_cat.shape == (10000,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R40KsLKaGMCL"
      },
      "source": [
        "The data is now ready to be used. ‚úÖ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpf95eNbGMCL"
      },
      "source": [
        "## (2) The Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MPTqwZBGMCL"
      },
      "source": [
        "### (2.1) Architecture and compilation of a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm5KBnA5GMCL"
      },
      "source": [
        "\n",
        "‚ùì **Question: CNN Architecture and compilation** ‚ùì\n",
        "\n",
        "Now, let's build a <u>Convolutional Neural Network</u> that has:\n",
        "\n",
        "\n",
        "- a `Conv2D` layer with 8 filters, each of size $(4, 4)$, an input shape suitable for your task, the `relu` activation function, and `padding='same'`\n",
        "- a `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "- a second `Conv2D` layer with 16 filters, each of size $(3, 3)$, and the `relu` activation function\n",
        "- a second `MaxPool2D` layer with a `pool_size` equal to $(2, 2)$\n",
        "\n",
        "\n",
        "- a `Flatten` layer\n",
        "- a first `Dense` layer with 10 neurons and the `relu` activation function\n",
        "- a last (predictive) layer that is suited for your task\n",
        "\n",
        "In the function that initializes this model, do not forget to include the <u>compilation of the model</u>, which:\n",
        "* optimizes the `categorical_crossentropy` loss function,\n",
        "* with the `adam` optimizer,\n",
        "* and the `accuracy` as the metrics\n",
        "\n",
        "(*Note: you could add more classification metrics if you want but the dataset is well balanced!*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rXP52m-EGMCM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import models\n",
        "\n",
        "\n",
        "def initialize_model():\n",
        "\n",
        "    model = models.Sequential()\n",
        "\n",
        "    ### First Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(8, (4,4), input_shape=(28, 28, 1), padding='same', activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Second Convolution & MaxPooling\n",
        "    model.add(layers.Conv2D(16, (3,3), input_shape=(28, 28, 1), activation=\"relu\"))\n",
        "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
        "\n",
        "    ### Flattening\n",
        "    model.add(layers.Flatten())\n",
        "\n",
        "    ### One Fully Connected layer - \"Fully Connected\" is equivalent to saying \"Dense\"\n",
        "    model.add(layers.Dense(10, activation='relu'))\n",
        "\n",
        "    ### Last layer - Classification Layer with 10 outputs corresponding to 10 digits\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "    ### Model compilation\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDw3RqzfGMCM"
      },
      "source": [
        "‚ùì **Question: number of trainable parameters in a convolutional layer** ‚ùì\n",
        "\n",
        "How many trainable parameters are there in your model?\n",
        "1. Compute them with ***model.summary( )*** first\n",
        "2. Recompute them manually to make sure you properly understood ***what influences the number of weights in a CNN***."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cZXp-cdGMCM",
        "outputId": "2db2bdce-bec4-46d5-af73-0739cdbd3226"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 28, 28, 8)         136       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 14, 14, 8)         0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 12, 12, 16)        1168      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 576)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                5770      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                110       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7184 (28.06 KB)\n",
            "Trainable params: 7184 (28.06 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Model Summary\n",
        "model = initialize_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fbs6FoYGMCM"
      },
      "source": [
        "### (2.2) Training a CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb70CHWyGMCM"
      },
      "source": [
        "‚ùì **Question: training a CNN** ‚ùì\n",
        "\n",
        "Initialize your model and fit it on the train data.\n",
        "- Do not forget to use a **Validation Set/Split** and an **Early Stopping criterion**.\n",
        "- Limit yourself to 5 epochs max in this challenge, just to save some precious time for the more advanced challenges!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "l--hu6_cGMCM"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "\n",
        "model = initialize_model() #initialize model\n",
        "\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train_cat,\n",
        "    batch_size=16,\n",
        "    epochs=5,\n",
        "    validation_split=0.3,\n",
        "    callbacks = [es],\n",
        "    shuffle=True,\n",
        "    verbose=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw3JVlsrGMCM"
      },
      "source": [
        "‚ùì **Question: How many iterations does the CNN perform per epoch** ‚ùì\n",
        "\n",
        "_Note: it has nothing to do with the fact that this is a CNN. This is related to the concept of forward/backward propagation already covered during the previous lecture on optimizers, fitting, and losses üòâ_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [
          "challengify"
        ],
        "id": "9LjvF2T9GMCM"
      },
      "source": [
        "> We have batch sizes of 16 and a total of 60,000 rows. Since we splited the training size by 30% it means we are only working with 70%, hence the iteration per epoch is 60,000 * 0.7 / 16 = 2,625 iterations per epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5AS40VoGMCM"
      },
      "source": [
        "<details>\n",
        "    <summary><i>Answer</i></summary>\n",
        "\n",
        "With `verbose = 1` when fitting your model, you have access to crucial information about your training procedure.\n",
        "    \n",
        "Remember that we've just trained our CNN model on $60000$ training images\n",
        "\n",
        "If the chosen batch size is 32:\n",
        "\n",
        "* For each epoch, we have $ \\large \\lceil \\frac{60000}{32} \\rceil = 1875$ minibatches <br/>\n",
        "* The _validation_split_ is equal to $0.3$ - which means that within one single epoch, there are:\n",
        "    * $ \\lceil 1875 \\times (1 - 0.3) \\rceil = \\lceil 1312.5 \\rceil = 1313$ batches are used to compute the `train_loss`\n",
        "    * $ 1875 - 1312 = 562 $ batches are used to compute the `val_loss`\n",
        "    * **The parameters are updated 1313 times per epoch** as there are 1313 forward/backward propagations per epoch !!!\n",
        "\n",
        "\n",
        "üëâ With so many updates of the weights within one epoch, you can understand why this CNN model converges even with a limited number of epochs.\n",
        "\n",
        "</details>    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhnjpK4SGMCP"
      },
      "source": [
        "### (2.3) Evaluating its performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij0fScSDGMCP"
      },
      "source": [
        "‚ùì **Question: Evaluating your CNN** ‚ùì\n",
        "\n",
        "What is your **`accuracy on the test set?`**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "tags": [
          "challengify"
        ],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPqy3QE1GMCQ",
        "outputId": "af42a70f-56a6-4621-f2ce-c0371076166d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0704 - accuracy: 0.9785\n",
            "The accuracy of the test set is: 0.9785\n"
          ]
        }
      ],
      "source": [
        "# Accuracy on the test set\n",
        "print(f'The accuracy of the test set is: {model.evaluate(X_test, y_test_cat)[1]:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSgVXQTSGMCQ"
      },
      "source": [
        "üéâ You should already be impressed by your CNN skills! Reaching over 95% accuracy!\n",
        "\n",
        "üî• You solved what was a very hard problem 30 years ago with your own CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2i7zz7mjGMCQ"
      },
      "source": [
        "üèÅ **Congratulations!**\n",
        "\n",
        "üíæ Don't forget to `git add/commit/push` your notebook...\n",
        "\n",
        "üöÄ ... and move on to the next challenge!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}